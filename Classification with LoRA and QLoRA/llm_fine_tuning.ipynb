{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816648c3",
   "metadata": {},
   "source": [
    "Prompt-Based Inference (No Fine-Tuning)\n",
    "Used a pre-trained instruction-tuned LLM:\n",
    "\n",
    "mistralai/Mistral-7B-Instruct-v0.1, or\n",
    "\n",
    "meta-llama/Llama-2-7b-chat-hf or any other model of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773ae283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# Install required libraries\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\", \"datasets\", \"torch\", \"accelerate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db6211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset loaded: 7600 examples\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load AG News dataset from Hugging Face\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "test_data = dataset[\"test\"]\n",
    "print(f\"Test dataset loaded: {len(test_data)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4459b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a006266acdd4e3e93b566eb7e4b524f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "cache_dir = \"./model_cache\"\n",
    "\n",
    "# Check if cache has valid model files\n",
    "def is_cache_valid(cache_path):\n",
    "    if not os.path.exists(cache_path):\n",
    "        return False\n",
    "    required_files = ['pytorch_model.bin', 'model.safetensors', 'config.json']\n",
    "    return any(os.path.exists(os.path.join(cache_path, f)) for f in required_files)\n",
    "\n",
    "# Load or download model\n",
    "if is_cache_valid(cache_dir):\n",
    "    print(\"Loading from cache...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cache_dir)\n",
    "    model = AutoModelForCausalLM.from_pretrained(cache_dir, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "else:\n",
    "    print(\"Downloading model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dc7e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping and prompt function created\n"
     ]
    }
   ],
   "source": [
    "# Define label mapping and create classification prompt\n",
    "label_map = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "\n",
    "def create_prompt(text):\n",
    "    return f\"\"\"Classify the following news headline into one of the categories: World, Sports, Business, Sci/Tech.\n",
    "\n",
    "Text: \"{text}\"\n",
    "Label:\"\"\"\n",
    "\n",
    "print(\"Label mapping and prompt function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f728f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample example: {'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\", 'label': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed on 100 examples\n"
     ]
    }
   ],
   "source": [
    "# Perform inference on test set (full dataset)\n",
    "from tqdm import tqdm\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# First, let's check the structure of test_data\n",
    "print(\"Sample example:\", test_data[0])\n",
    "\n",
    "for i in tqdm(range(len(test_data)), desc=\"Baseline inference\"):\n",
    "    example = test_data[i]\n",
    "    \n",
    "    # Access the text and label from the example\n",
    "    # dataset items may be dict-like\n",
    "    if isinstance(example, dict):\n",
    "        text = example.get(\"text\") or example.get(\"content\")\n",
    "        label = example.get(\"label\")\n",
    "    else:\n",
    "        # fallback if dataset returns tuples\n",
    "        try:\n",
    "            text, label = example\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    if text is None:\n",
    "        continue\n",
    "    \n",
    "    prompt = create_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10, do_sample=False)\n",
    "    \n",
    "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract only the generated part (after the prompt)\n",
    "    prediction_text = full_output[len(prompt):].strip()\n",
    "    \n",
    "    # Try to match prediction to a label\n",
    "    matched_label = \"Unknown\"\n",
    "    for lbl in label_map.values():\n",
    "        if lbl.lower() in prediction_text.lower():\n",
    "            matched_label = lbl\n",
    "            break\n",
    "    \n",
    "    predictions.append(matched_label)\n",
    "    true_labels.append(label_map[label])\n",
    "\n",
    "print(f\"Baseline inference completed on {len(predictions)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70a3dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.7600\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.44      1.00      0.62        12\n",
      "    Sci/Tech       0.77      0.65      0.71        37\n",
      "      Sports       0.89      0.81      0.85        21\n",
      "       World       1.00      0.77      0.87        30\n",
      "\n",
      "    accuracy                           0.76       100\n",
      "   macro avg       0.78      0.81      0.76       100\n",
      "weighted avg       0.83      0.76      0.77       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy and evaluate baseline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Baseline Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ee317cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[12  0  0  0]\n",
      " [13 24  0  0]\n",
      " [ 1  3 17  0]\n",
      " [ 1  4  2 23]]\n",
      "\n",
      "Labels order: ['Business', 'Sci/Tech', 'Sports', 'World']\n"
     ]
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get unique labels\n",
    "labels_list = sorted(label_map.values())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions, labels=labels_list)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels_list, \n",
    "            yticklabels=labels_list,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - LLM Baseline Predictions')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nLabels order:\", labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb004e4c",
   "metadata": {},
   "source": [
    "# Fine-Tuning with LoRA (Low-Rank Adaptation)\n",
    "\n",
    "## Overview\n",
    "LoRA is a parameter-efficient fine-tuning method that reduces the number of trainable parameters by adding low-rank decomposition matrices to the model. Instead of updating all model weights, we only train small adapter modules.\n",
    "\n",
    "## Key Concepts\n",
    "- **LoRA**: Low-Rank Adaptation - adds trainable low-rank matrices to pre-trained weights\n",
    "- **PEFT Library**: Parameter-Efficient Fine-Tuning library from Hugging Face\n",
    "- **Adapter Injection**: Injects LoRA modules into the model's linear layers\n",
    "- **Memory Efficient**: Reduces memory usage and training time significantly\n",
    "\n",
    "## Steps to Implement\n",
    "1. Install PEFT library\n",
    "2. Prepare the training dataset with proper formatting\n",
    "3. Create and inject LoRA adapters\n",
    "4. Configure training parameters\n",
    "5. Train the model on labeled data\n",
    "6. Evaluate on test set\n",
    "7. Compare accuracy with baseline\n",
    "\n",
    "## Expected Outcomes\n",
    "- LoRA-finetuned model should outperform the baseline prompt-based approach\n",
    "- Significant reduction in trainable parameters compared to full fine-tuning\n",
    "- Faster training and inference compared to full model updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6213b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT library installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install PEFT library for LoRA\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"peft\", \"bitsandbytes\"])\n",
    "print(\"PEFT library installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training dataset with proper formatting\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load training data\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "# Create formatted dataset for training\n",
    "def format_training_data(examples):\n",
    "    \"\"\"Format examples into conversation format\"\"\"\n",
    "    formatted_texts = []\n",
    "    for i in range(len(examples[\"text\"])):\n",
    "        text = examples[\"text\"][i]\n",
    "        label = label_map[examples[\"label\"][i]]\n",
    "        \n",
    "        # Format as instruction-response pair\n",
    "        formatted_text = f\"\"\"Classify the following news headline into one of the categories: World, Sports, Business, Sci/Tech.\n",
    "\n",
    "Text: \"{text}\"\n",
    "Label: {label}\"\"\"\n",
    "        formatted_texts.append(formatted_text)\n",
    "    \n",
    "    return {\"text\": formatted_texts}\n",
    "\n",
    "# Format training data\n",
    "train_formatted = train_data.map(\n",
    "    format_training_data,\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    remove_columns=train_data.column_names\n",
    ")\n",
    "\n",
    "print(f\"Training dataset prepared: {len(train_formatted)} examples\")\n",
    "print(\"Sample formatted text:\")\n",
    "print(train_formatted[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure LoRA adapters\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rank of the low-rank adaptation\n",
    "    lora_alpha=32,  # Scaling factor for LoRA weights\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Which layers to apply LoRA to\n",
    "    lora_dropout=0.05,  # Dropout for LoRA layers\n",
    "    bias=\"none\",  # Don't train bias parameters\n",
    "    task_type=TaskType.CAUSAL_LM  # Task type (causal language modeling)\n",
    ")\n",
    "\n",
    "# Create PEFT model by wrapping the base model\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "peft_model.print_trainable_parameters()\n",
    "print(\"\\nLoRA adapters injected successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e24900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training with proper tokenization\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Tokenize the text\"\"\"\n",
    "    texts = examples[\"text\"]\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # Set labels same as input_ids for causal language modeling\n",
    "    encodings[\"labels\"] = encodings[\"input_ids\"].clone()\n",
    "    return encodings\n",
    "\n",
    "# Tokenize training data\n",
    "train_tokenized = train_formatted.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "print(f\"Training data tokenized: {len(train_tokenized)} examples\")\n",
    "print(\"Sample tokenized example keys:\", train_tokenized[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training parameters and trainer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_model_results\",  # Output directory for model checkpoints\n",
    "    num_train_epochs=3,  # Number of training epochs\n",
    "    per_device_train_batch_size=4,  # Batch size per device\n",
    "    gradient_accumulation_steps=4,  # Accumulate gradients over this many steps\n",
    "    warmup_steps=100,  # Number of warmup steps\n",
    "    weight_decay=0.01,  # Weight decay for regularization\n",
    "    logging_dir=\"./logs\",  # Directory for logs\n",
    "    logging_steps=10,  # Log every N steps\n",
    "    save_steps=50,  # Save checkpoint every N steps\n",
    "    save_total_limit=2,  # Keep only last 2 checkpoints\n",
    "    learning_rate=5e-4,  # Learning rate for training\n",
    "    optim=\"paged_adamw_8bit\",  # Optimizer\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with LoRA adapters\n",
    "import time\n",
    "\n",
    "print(\"Starting LoRA fine-tuning...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time) / 60  # Convert to minutes\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training completed in {training_time:.2f} minutes\")\n",
    "print(\"LoRA model saved to ./lora_model_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LoRA fine-tuned model on test set (full dataset)\n",
    "from tqdm import tqdm\n",
    "lora_predictions = []\n",
    "lora_true_labels = []\n",
    "\n",
    "print(\"Running inference with LoRA fine-tuned model on full test set...\")\n",
    "\n",
    "for i in tqdm(range(len(test_data)), desc=\"LoRA inference\"):\n",
    "    example = test_data[i]\n",
    "    \n",
    "    if isinstance(example, dict):\n",
    "        text = example.get(\"text\") or example.get(\"content\")\n",
    "        label = example.get(\"label\")\n",
    "    else:\n",
    "        try:\n",
    "            text, label = example\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    if text is None:\n",
    "        continue\n",
    "    \n",
    "    prompt = create_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(peft_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = peft_model.generate(**inputs, max_new_tokens=10, do_sample=False)\n",
    "    \n",
    "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    prediction_text = full_output[len(prompt):].strip()\n",
    "    \n",
    "    matched_label = \"Unknown\"\n",
    "    for lbl in label_map.values():\n",
    "        if lbl.lower() in prediction_text.lower():\n",
    "            matched_label = lbl\n",
    "            break\n",
    "    \n",
    "    lora_predictions.append(matched_label)\n",
    "    lora_true_labels.append(label_map[label])\n",
    "\n",
    "print(f\"LoRA inference completed on {len(lora_predictions)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LoRA accuracy with baseline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calculate LoRA accuracy\n",
    "lora_accuracy = accuracy_score(lora_true_labels, lora_predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: Baseline vs LoRA Fine-Tuned\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Baseline (Prompt-Based) Accuracy: {accuracy:.4f}\")\n",
    "print(f\"LoRA Fine-Tuned Accuracy:         {lora_accuracy:.4f}\")\n",
    "print(f\"Improvement:                      {(lora_accuracy - accuracy):.4f} ({((lora_accuracy - accuracy) / accuracy * 100):.2f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nLoRA Classification Report:\")\n",
    "print(classification_report(lora_true_labels, lora_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix for LoRA model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get unique labels\n",
    "labels_list = sorted(label_map.values())\n",
    "\n",
    "# Compute confusion matrix for LoRA\n",
    "lora_cm = confusion_matrix(lora_true_labels, lora_predictions, labels=labels_list)\n",
    "\n",
    "# Plot confusion matrices side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Baseline confusion matrix\n",
    "cm_baseline = confusion_matrix(true_labels, predictions, labels=labels_list)\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels_list, \n",
    "            yticklabels=labels_list,\n",
    "            ax=axes[0],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Baseline (Prompt-Based) Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# LoRA confusion matrix\n",
    "sns.heatmap(lora_cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=labels_list, \n",
    "            yticklabels=labels_list,\n",
    "            ax=axes[1],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[1].set_title('LoRA Fine-Tuned Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLoRA Confusion Matrix:\")\n",
    "print(lora_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8c96af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed/verified bitsandbytes, accelerate, peft, safetensors\n"
     ]
    }
   ],
   "source": [
    "# Install / ensure required libraries for QLoRA\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Install required packages if missing\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"bitsandbytes\", \"accelerate\", \"peft\", \"safetensors\"]) \n",
    "print(\"Installed/verified bitsandbytes, accelerate, peft, safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d96310c",
   "metadata": {},
   "source": [
    "# Task 3: Fine-Tuning with QLoRA (Quantized LoRA)\n",
    "\n",
    "## Overview\n",
    "QLoRA loads a large pre-trained model in 4-bit quantized precision (using bitsandbytes) and applies LoRA adapters on top. This lets us fine-tune very large models on a single GPU with minimal memory by:\n",
    "\n",
    "- Quantizing weights to 4-bit (NF4 or similar) using `bitsandbytes` and `BitsAndBytesConfig`.\n",
    "- Wrapping the quantized model with PEFT LoRA adapters so only adapter parameters are trained.\n",
    "- Training using transformers' `Trainer` with optimizers compatible with quantized weights (e.g., 8-bit optimizers provided by bitsandbytes).\n",
    "\n",
    "## Steps in this notebook\n",
    "1. Install required libraries (bitsandbytes, accelerate, peft if not present)\n",
    "2. Prepare a BitsAndBytes quantization config and load the model in 4-bit\n",
    "3. Inject LoRA adapters into the quantized model\n",
    "4. Tokenize the formatted training dataset and create a Trainer\n",
    "5. Fine-tune the model (LoRA parameters only)\n",
    "6. Evaluate on the AG News test set and report accuracy\n",
    "7. Show confusion matrix and compare with previous approaches\n",
    "\n",
    "Notes:\n",
    "- Training a large model even with QLoRA can be slow; consider running a small subset first for debugging.\n",
    "- Adjust `bnb_4bit_*` parameters in the quantization config depending on your hardware and `transformers`/`bitsandbytes` versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a27fc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bitsandbytes UPGRADED to latest\n",
      " accelerate, peft, safetensors installed/verified\n"
     ]
    }
   ],
   "source": [
    "# (QLoRA) Install / verify extra dependencies - UPGRADE bitsandbytes\n",
    "import sys, subprocess\n",
    "\n",
    "# Force upgrade of bitsandbytes to latest version\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"bitsandbytes\"])\n",
    "# Install other dependencies\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"accelerate\", \"peft\", \"safetensors\"]) \n",
    "print(\" bitsandbytes UPGRADED to latest\")\n",
    "print(\" accelerate, peft, safetensors installed/verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640a7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading quantized tokenizer and model (4-bit). This can take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0242aa090ce49b3a03a9b584599a11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51be6ad21834ea3854577e1485c6d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f78871d25942fe980d7762cfb5a78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eba8d0170b848d5b5a40a81218db7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65dbb9834a94d7396e45a437d5a4ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5101de966eb4aefa3dc1bc3d14a55df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8c9ad537154a3183a34d7878a76a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba73c07ec904311a658e5b1e232d3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a45a1d1308459d8920e2787da1e741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer and model in 4-bit using BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "print(\"Loading quantized tokenizer and model (4-bit). This can take a while...\")\n",
    "\n",
    "tokenizer_q = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model_q = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=False\n",
    ")\n",
    "\n",
    "print(\"Quantized model loaded (4-bit).\")\n",
    "if hasattr(model_q, 'hf_device_map'):\n",
    "    print(\"Device map:\", model_q.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c98483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.0470\n",
      "LoRA adapters injected into 4-bit model\n"
     ]
    }
   ],
   "source": [
    "# Inject LoRA adapters into the quantized model (PEFT)\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "lora_config_q = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "peft_q_model = get_peft_model(model_q, lora_config_q)\n",
    "peft_q_model.print_trainable_parameters()\n",
    "print(\"LoRA adapters injected into 4-bit model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823cd051",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_formatted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     enc[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = enc[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m enc\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_tokenized_q = \u001b[43mtrain_formatted\u001b[49m.map(\n\u001b[32m     10\u001b[39m     preprocess_q,\n\u001b[32m     11\u001b[39m     batched=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     12\u001b[39m     batch_size=\u001b[32m32\u001b[39m,\n\u001b[32m     13\u001b[39m     remove_columns=[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQLoRA training data tokenized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_tokenized_q)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m examples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSample keys:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(train_tokenized_q[\u001b[32m0\u001b[39m].keys()))\n",
      "\u001b[31mNameError\u001b[39m: name 'train_formatted' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenize formatted training data for QLoRA training\n",
    "# We reuse `train_formatted` created earlier (instruction-response strings)\n",
    "\n",
    "def preprocess_q(examples):\n",
    "    enc = tokenizer_q(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "    enc[\"labels\"] = enc[\"input_ids\"].copy()\n",
    "    return enc\n",
    "\n",
    "train_tokenized_q = train_formatted.map(\n",
    "    preprocess_q,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "print(f\"QLoRA training data tokenized: {len(train_tokenized_q)} examples\")\n",
    "print(\"Sample keys:\", list(train_tokenized_q[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training arguments for QLoRA and initialize Trainer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args_q = TrainingArguments(\n",
    "    output_dir=\"./qlora_model_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./qlora_logs\",\n",
    "    logging_steps=20,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    ")\n",
    "\n",
    "trainer_q = Trainer(\n",
    "    model=peft_q_model,\n",
    "    args=training_args_q,\n",
    "    train_dataset=train_tokenized_q,\n",
    "    tokenizer=tokenizer_q,\n",
    ")\n",
    "\n",
    "print(\"QLoRA Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune QLoRA (LoRA on 4-bit) - run training\n",
    "import time\n",
    "\n",
    "print(\"Starting QLoRA fine-tuning...\")\n",
    "start = time.time()\n",
    "trainer_q.train()\n",
    "end = time.time()\n",
    "print(f\"QLoRA training finished in {(end-start)/60:.2f} minutes\")\n",
    "print(\"Model checkpoints saved to ./qlora_model_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate QLoRA fine-tuned model on test set (full dataset)\n",
    "from tqdm import tqdm\n",
    "qlora_predictions = []\n",
    "qlora_true_labels = []\n",
    "\n",
    "print(\"Running inference with QLoRA fine-tuned model on full test set...\")\n",
    "for i in tqdm(range(len(test_data)), desc=\"QLoRA inference\"):\n",
    "    example = test_data[i]\n",
    "    if isinstance(example, dict):\n",
    "        text = example.get(\"text\") or example.get(\"content\")\n",
    "        label = example.get(\"label\")\n",
    "    else:\n",
    "        try:\n",
    "            text, label = example\n",
    "        except Exception:\n",
    "            continue\n",
    "    if text is None:\n",
    "        continue\n",
    "    prompt = create_prompt(text)\n",
    "    inputs = tokenizer_q(prompt, return_tensors=\"pt\").to(peft_q_model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = peft_q_model.generate(**inputs, max_new_tokens=10, do_sample=False)\n",
    "    full_output = tokenizer_q.decode(outputs[0], skip_special_tokens=True)\n",
    "    pred_text = full_output[len(prompt):].strip()\n",
    "    matched = \"Unknown\"\n",
    "    for lbl in label_map.values():\n",
    "        if lbl.lower() in pred_text.lower():\n",
    "            matched = lbl\n",
    "            break\n",
    "    qlora_predictions.append(matched)\n",
    "    qlora_true_labels.append(label_map[label])\n",
    "\n",
    "print(f\"QLoRA inference completed on {len(qlora_predictions)} examples\")\n",
    "\n",
    "# Compute accuracy\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "qlora_accuracy = accuracy_score(qlora_true_labels, qlora_predictions)\n",
    "print(f\"QLoRA Accuracy: {qlora_accuracy:.4f}\")\n",
    "print(\"\\nQLoRA Classification Report:\")\n",
    "print(classification_report(qlora_true_labels, qlora_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43731b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare QLoRA vs LoRA vs Baseline and show confusion matrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_list = sorted(label_map.values())\n",
    "\n",
    "# Confusion matrices\n",
    "cm_baseline = confusion_matrix(true_labels, predictions, labels=labels_list)\n",
    "cm_lora = confusion_matrix(lora_true_labels, lora_predictions, labels=labels_list) if 'lora_predictions' in globals() else None\n",
    "cm_qlora = confusion_matrix(qlora_true_labels, qlora_predictions, labels=labels_list)\n",
    "\n",
    "# Plot\n",
    "ncols = 2 if cm_lora is None else 3\n",
    "fig, axes = plt.subplots(1, ncols, figsize=(6*ncols, 5))\n",
    "\n",
    "# Baseline\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', xticklabels=labels_list, yticklabels=labels_list, ax=axes[0])\n",
    "axes[0].set_title('Baseline')\n",
    "\n",
    "# LoRA\n",
    "if cm_lora is not None:\n",
    "    sns.heatmap(cm_lora, annot=True, fmt='d', cmap='Greens', xticklabels=labels_list, yticklabels=labels_list, ax=axes[1])\n",
    "    axes[1].set_title('LoRA')\n",
    "\n",
    "# QLoRA\n",
    "sns.heatmap(cm_qlora, annot=True, fmt='d', cmap='Oranges', xticklabels=labels_list, yticklabels=labels_list, ax=axes[-1])\n",
    "axes[-1].set_title('QLoRA')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Baseline accuracy:', accuracy)\n",
    "if 'lora_predictions' in globals():\n",
    "    print('LoRA accuracy:', lora_accuracy)\n",
    "print('QLoRA accuracy:', qlora_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
