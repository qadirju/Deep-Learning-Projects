{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ab7ce0",
   "metadata": {},
   "source": [
    "# Context-Aware Chatbot Using LangChain and RAG\n",
    "\n",
    "This project builds a conversational chatbot that retrieves information from a knowledge base using Retrieval-Augmented Generation (RAG) while maintaining conversation context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27e69f",
   "metadata": {},
   "source": [
    "## Project Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b683bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52acc522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages...\n",
      "✓ All packages installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"langchain\",\n",
    "    \"langchain-huggingface\",\n",
    "    \"langchain-community\",\n",
    "    \"langchain-text-splitters\",\n",
    "    \"sentence-transformers\",\n",
    "    \"faiss-cpu\",\n",
    "    \"transformers\",\n",
    "    \"torch\",\n",
    "    \"streamlit\"\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "print(\"✓ All packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359ed215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import Core Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from typing import List, Dict\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9e500",
   "metadata": {},
   "source": [
    "## 1. Create Sample Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process documents: Split into chunks and create embeddings\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "document_chunks = text_splitter.create_documents(sample_documents)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create FAISS vector store\n",
    "vector_store = FAISS.from_documents(document_chunks, embeddings)\n",
    "\n",
    "print(f\"✓ Split documents into {len(document_chunks)} chunks\")\n",
    "print(f\"✓ Generated embeddings with dimension: {embeddings.embed_query('test').__len__()}\")\n",
    "print(f\"✓ Created FAISS vector store successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample knowledge base\n",
    "sample_documents = [\n",
    "    \"\"\"LangChain is a framework for developing applications powered by language models. \n",
    "    It enables applications that are data-aware and agentic, allowing them to interact with \n",
    "    their environment and use external tools for computation and information retrieval.\"\"\",\n",
    "    \n",
    "    \"\"\"Retrieval-Augmented Generation (RAG) combines retrieval and generation capabilities. \n",
    "    It retrieves relevant documents from a knowledge base and uses them to augment the prompt \n",
    "    for better, more contextual responses from language models.\"\"\",\n",
    "    \n",
    "    \"\"\"Vector databases like FAISS store embeddings of documents, enabling semantic search. \n",
    "    When a user query is converted to embeddings, the database finds similar documents \n",
    "    based on vector similarity, which is faster than traditional keyword matching.\"\"\",\n",
    "    \n",
    "    \"\"\"Sentence Transformers are pre-trained models that encode text into dense vector representations. \n",
    "    These embeddings capture semantic meaning, allowing documents with similar meaning to have \n",
    "    similar vectors regardless of exact wording.\"\"\"\n",
    "]\n",
    "\n",
    "print(f\"✓ Created {len(sample_documents)} sample documents for knowledge base\")\n",
    "print(f\"Sample preview: {sample_documents[0][:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
